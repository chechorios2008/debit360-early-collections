# ðŸ“Š Capacidad AnalÃ­tica Operativa para OptimizaciÃ³n de Cobranza en Mora Temprana

SoluciÃ³n analÃ­tica endâ€‘toâ€‘end para identificar obligaciones con **alta probabilidad de pago exclusivamente por dÃ©bito recurrente** (recurrencia â‰¥ 40%), optimizando la asignaciÃ³n de gestiÃ³n de cobranza en mora temprana (1â€“30 dÃ­as) y reduciendo costos operativos.

---

## ðŸŽ¯ Objetivo del Proyecto

DiseÃ±ar una soluciÃ³n completa que permita:

- Integrar mÃºltiples fuentes (nivel clienteâ€“obligaciÃ³n).
- Construir un modelo de **clasificaciÃ³n binaria** (probabilidad de pago por dÃ©bito recurrente).
- Definir un umbral operativo (recurrencia â‰¥ 40%) y criterios de decisiÃ³n.
- Operacionalizar resultados (scoring + consumo por negocio) con trazabilidad.

**Resultado esperado:** identificar obligaciones que **NO requieren gestiÃ³n intensiva** porque tienen alta probabilidad de pago automÃ¡tico por dÃ©bito recurrente.

---

## ðŸ§© Problema de Negocio

La cobranza tradicional asigna recursos sin diferenciar entre:

- Obligaciones con riesgo real de no pago.
- Obligaciones que pagan de forma natural por **dÃ©bito recurrente**.

Esto genera:

- Costos innecesarios de gestiÃ³n.
- Menor eficiencia operativa.
- Uso subÃ³ptimo de canales y estrategias.

---

## ðŸ—ï¸ Arquitectura de la SoluciÃ³n

DiseÃ±o bajo enfoque **Data + ML + OperacionalizaciÃ³n** siguiendo buenas prÃ¡cticas de ingenierÃ­a y MLOps.

ðŸ“„ Ver detalle en: [`ARCHITECTURE.md`](./ARCHITEincipales:**
- **Data Storage Layer** â†’ organizaciÃ³n RAW / SILVER / GOLD
- **Data Processing Layer** â†’ procesamiento con Apache Spark
- **ML & MLOps Layer** â†’ entrenamiento + tracking con MLflow
- **Serving Layer** â†’ exposiciÃ³n/ejecuciÃ³n vÃ­a FastAPI (batch/online)
- **Business Consumption Layer** â†’ Power BI / automatizaciÃ³n (n8n)

---

## ðŸ”„ Flujo del Proceso (alto nivel)

1. Ingesta de datos crudos (CSV).
2. Limpieza, estandarizaciÃ³n y enriquecimiento (Spark).
3. Feature Engineering.
4. Entrenamiento del modelo.
5. EvaluaciÃ³n (AUC + mÃ©tricas operativas).
6. Tracking de experimentos (MLflow).
7. Scoring (probabilidades).
8. Consumo operativo + visualizaciÃ³n.

---

## âš™ï¸ Stack TecnolÃ³gico

- **Procesamiento:** Apache Spark (PySpark)
- **Data:** Pandas / DuckDB / PyArrow
- **ML:** scikitâ€‘learn
- **MLOps:** MLflow
- **Serving:** FastAPI + Uvicorn
- **Calidad:** Pytest / Ruff / Black / Isort / Mypy
- **VisualizaciÃ³n:** Power BI (fuera de este repo) / notebooks

---

## âœ… Requisitos del Entorno

- **Python 3.11 (64â€‘bit)** recomendado (entorno objetivo local y base para despliegue).
- Windows/Linux compatibles (comandos abajo incluyen Windows).

---

## ðŸ“¦ Dependencias y Reproducibilidad

Este repositorio usa **dos archivos**:

- `requirements.txt`: dependencias directas del proyecto (curadas).
- `requirements-lock.txt`: snapshot exacto del entorno (**generado con `pip freeze`**).

> Nota: `pip freeze` **reporta lo instalado** (incluye dependencias transitivas) y **no calcula un lockfile/solver result**, pero sirve como snapshot reproducible de entorno. [1](https://pip.pypa.io/en/stable/cli/pip_freeze/)

### Â¿CuÃ¡l usar?
- Para instalar **rÃ¡pido y flexible**: `requirements.txt`
- Para replicar el entorno **1:1 (reproducible)**: `requirements-lock.txt`

---

## ðŸš€ EjecuciÃ³n Local (Windows)

### 1) Crear y activar entorno virtual (Python 3.11)

cd C:\Users\serrios\01_prueba_analitico_4\op_cobro
py -3.11 -m venv .venv
.\.venv\Scripts\activate
python --version

## ðŸ”Ž InspecciÃ³n rÃ¡pida de la base DuckDB (schemas/tablas)
###
La base local se persiste en: `database/analytics.duckdb`.

### Ver esquemas (schemas) disponibles
DuckDB expone metadatos vÃ­a `information_schema`. Para listar los esquemas Ãºnicos:

#### bash
python -c "import duckdb; con=duckdb.connect('database/analytics.duckdb'); print(con.execute(\"SELECT DISTINCT schema_name FROM information_schema.schemata ORDER BY schema_name\").fetchdf()); con.close()"

## Data Quality Checks (RAW)

Este proyecto incluye un script de validaciÃ³n de calidad de datos para las tablas del esquema `raw` en DuckDB.

### Â¿QuÃ© valida?
- **Existencia de tablas** y conteo de registros.
- **Nulos en columnas clave** (`num_doc`, `obl17`, `f_analisis`) si existen.
- **Duplicados** en `raw.clientes` por unidad analÃ­tica `(num_doc, obl17, f_analisis)`.
- **Integridad referencial**: registros huÃ©rfanos en `raw.moras` respecto a `raw.clientes` (por `obl17`).

### Requisitos
- Python 3.10+ (recomendado)
- Entorno virtual activo (`.venv`)
- Dependencias instaladas