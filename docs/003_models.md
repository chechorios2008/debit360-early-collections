üß† Justificaci√≥n del Modelo de Machine Learning: train_model.py

Este documento detalla los criterios t√©cnicos y las decisiones de dise√±o adoptadas para la fase de modelado predictivo, asegurando la alineaci√≥n con los requerimientos de la Gerencia de Inteligencia de Originaci√≥n y Cobranza.

1. Estrategia de Particionamiento Temporal (Train/Test/OOT)
Para garantizar la robustez estad√≠stica y la estabilidad del modelo, se rechaz√≥ el uso de particionamiento aleatorio tradicional. En su lugar, se implement√≥ un esquema de validaci√≥n fuera de tiempo (Out-of-Time - OOT):

Segmento Train/Test (Hist√≥rico): Utilizado para el aprendizaje de patrones y ajuste de hiperpar√°metros.

Segmento OOT (Validaci√≥n Externa): Correspondiente al mes m√°s reciente de la data (f_analisis m√°ximo, Septiembre 2025). Este conjunto de datos se mantuvo aislado durante todo el proceso de entrenamiento.

Justificaci√≥n: En modelos de cobranza, el comportamiento de pago presenta estacionalidad y dependencia temporal. Evaluar el modelo con un mes "futuro" respecto al entrenamiento permite medir el Concept Drift y asegurar que la probabilidad estimada sea confiable para la operaci√≥n actual.

2. Selecci√≥n del Algoritmo: XGBoost Classifier
Se seleccion√≥ XGBoost (Extreme Gradient Boosting) como motor de inferencia principal debido a sus capacidades superiores en entornos financieros:

Manejo Nativo de Sparsity: Dado que el proceso de integraci√≥n de fuentes (Joins) result√≥ en un dataset con alta presencia de valores nulos o ceros (ausencia de gestiones o transacciones en ciertos canales), XGBoost gestiona estas "ramas vac√≠as" de forma √≥ptima sin requerir imputaciones artificiales que distorsionen la distribuci√≥n original.

Captura de Interacciones Complejas: El modelo identifica relaciones no lineales entre variables (ej. el efecto combinado de ser un cliente digital y tener excedentes de pago), superando la capacidad de una regresi√≥n log√≠stica tradicional.

Control de Overfitting: Mediante par√°metros de regularizaci√≥n (Gamma, Lambda), se garantiza que el modelo aprenda tendencias generales y no ruidos espec√≠ficos del dataset de entrenamiento.

3. Trazabilidad y Gobierno con MLflow
Siguiendo buenas pr√°cticas de MLOps, el script integra MLflow para la gesti√≥n del ciclo de vida del modelo:

Reproducibilidad: Registro de cada experimento, incluyendo hiperpar√°metros y versiones de los datos.

M√©tricas de Desempe√±o: Monitoreo centralizado del AUC (Area Under the Curve) tanto en el set de Test como en el OOT para detectar degradaci√≥n de performance.

4. Definici√≥n de la Variable Respuesta (Target)
El target se construy√≥ bajo una l√≥gica de negocio operativa:

Target = 1: Obligaciones que presentan pagos exclusivamente por canal d√©bito y cumplen con el umbral de recurrencia ‚â• 40%.

Target = 0: Otros comportamientos de pago.

Objetivo de Negocio: Este enfoque permite al modelo identificar con precisi√≥n el segmento "auto-pagador", permitiendo al banco excluir estas obligaciones de las campa√±as de gesti√≥n intensiva, generando un ahorro directo en costos de cobranza.

5. Evaluaci√≥n de Estabilidad
La m√©trica de √©xito principal es el AUC. Se considera un modelo exitoso si la diferencia de AUC entre el set de Test y el OOT es m√≠nima, validando que el modelo es capaz de generalizar y mantener su poder discriminatorio en el tiempo.

# Para la visualizaci√≥n del rendimiento en MLFLOW.
mlflow ui --port 5000